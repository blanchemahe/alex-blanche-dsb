{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b8a02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Chemins\n",
    "TEST_PATH = \"/Users/alexandre/Desktop/X/Python for Data Science/Projet Final Churn/test.parquet\"\n",
    "EXAMPLE_PATH = \"/Users/alexandre/Desktop/X/Python for Data Science/Projet Final Churn/example_submission.csv\"\n",
    "MODEL_FILE = \"xgb_final_optimized.pkl\"\n",
    "OUTPUT_FILE = \"submission_optimized.csv\"\n",
    "\n",
    "print(\"‚úÖ Configuration charg√©e.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25678fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Chargement du fichier Test...\n",
      "üìÖ Date de r√©f√©rence (T_test) : 2018-11-20 00:00:00\n",
      "üë• Utilisateurs √† pr√©dire : 2904\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥ Chargement du fichier Test...\")\n",
    "test_df = pd.read_parquet(TEST_PATH)\n",
    "\n",
    "# Conversion des dates\n",
    "test_df[\"ts\"] = pd.to_datetime(test_df[\"ts\"], unit=\"ms\")\n",
    "test_df[\"date\"] = test_df[\"ts\"].dt.date\n",
    "\n",
    "# La date \"actuelle\" pour le test est la derni√®re date du fichier\n",
    "T_test = test_df[\"ts\"].max()\n",
    "print(f\"üìÖ Date de r√©f√©rence (T_test) : {T_test}\")\n",
    "\n",
    "# Liste des utilisateurs √† pr√©dire\n",
    "test_users = test_df[\"userId\"].unique()\n",
    "print(f\"üë• Utilisateurs √† pr√©dire : {len(test_users)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c91356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Reconstruction des features (Globales + Comportement)...\n",
      "‚úÖ Features de base calcul√©es.\n"
     ]
    }
   ],
   "source": [
    "print(\"üèóÔ∏è Reconstruction des features (Globales + Comportement)...\")\n",
    "\n",
    "# 1. Features Globales\n",
    "global_feats = test_df.groupby(\"userId\").agg({\n",
    "    \"ts\": \"max\",\n",
    "    \"date\": \"nunique\",\n",
    "    \"sessionId\": \"nunique\",\n",
    "    \"length\": \"sum\",\n",
    "    \"registration\": \"min\"\n",
    "}).reset_index()\n",
    "\n",
    "global_feats.columns = [\"userId\", \"last_ts\", \"n_active_days\", \"n_sessions\", \"total_listening_time\", \"registration_ts\"]\n",
    "\n",
    "# Conversion et calculs\n",
    "global_feats[\"registration_ts\"] = pd.to_datetime(global_feats[\"registration_ts\"], unit=\"ms\")\n",
    "global_feats[\"recency_days\"] = (T_test - global_feats[\"last_ts\"]).dt.days\n",
    "global_feats[\"account_age_days\"] = (T_test - global_feats[\"registration_ts\"]).dt.days\n",
    "global_feats[\"avg_daily_listen\"] = global_feats[\"total_listening_time\"] / (global_feats[\"account_age_days\"] + 1)\n",
    "\n",
    "# 2. Features Comportementales (Pouces, Erreurs...)\n",
    "page_counts = pd.pivot_table(\n",
    "    test_df, index=\"userId\", columns=\"page\", values=\"ts\", aggfunc=\"count\", fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "useful_pages = [\"Thumbs Up\", \"Thumbs Down\", \"Roll Advert\", \"Error\", \"Upgrade\", \"Downgrade\", \"Add to Playlist\"]\n",
    "cols_to_keep = [\"userId\"] + [col for col in useful_pages if col in page_counts.columns]\n",
    "behavior_df = page_counts[cols_to_keep].copy()\n",
    "\n",
    "# Ratio de Satisfaction\n",
    "if \"Thumbs Up\" in behavior_df and \"Thumbs Down\" in behavior_df:\n",
    "    behavior_df[\"satisfaction_ratio\"] = behavior_df[\"Thumbs Up\"] / (behavior_df[\"Thumbs Down\"] + 1)\n",
    "\n",
    "print(\"‚úÖ Features de base calcul√©es.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f08c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Reconstruction des features 'Trends'...\n",
      "‚úÖ Features Trends calcul√©es.\n"
     ]
    }
   ],
   "source": [
    "print(\"üìà Reconstruction des features 'Trends'...\")\n",
    "\n",
    "# 1. Fen√™tre r√©cente (14 jours avant la fin du test)\n",
    "T_recent = T_test - pd.Timedelta(days=14)\n",
    "test_recent = test_df[test_df[\"ts\"] >= T_recent]\n",
    "\n",
    "# 2. Activit√© r√©cente\n",
    "recent_stats = test_recent.groupby(\"userId\").agg({\n",
    "    \"length\": \"sum\"\n",
    "}).reset_index().rename(columns={\"length\": \"listen_time_recent\"})\n",
    "\n",
    "# 3. Fusion et Calcul des Ratios\n",
    "trends = global_feats[[\"userId\", \"avg_daily_listen\"]].merge(recent_stats, on=\"userId\", how=\"left\").fillna(0)\n",
    "\n",
    "trends[\"avg_daily_listen_recent\"] = trends[\"listen_time_recent\"] / 14\n",
    "trends[\"trend_listening\"] = trends[\"avg_daily_listen_recent\"] / (trends[\"avg_daily_listen\"] + 0.01)\n",
    "\n",
    "print(\"‚úÖ Features Trends calcul√©es.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6c03c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Extraction des features techniques SUR LE TEST...\n"
     ]
    }
   ],
   "source": [
    "# === A AJOUTER DANS NOTEBOOK 03 (Avant la fusion finale) ===\n",
    "print(\"üíª Extraction des features techniques SUR LE TEST...\")\n",
    "\n",
    "# Attention : on travaille sur test_df ici\n",
    "last_agent_test = test_df.sort_values(\"ts\").groupby(\"userId\")[\"userAgent\"].last().reset_index()\n",
    "\n",
    "last_agent_test[\"is_mac\"] = last_agent_test[\"userAgent\"].str.contains(\"Macintosh\", case=False, na=False).astype(int)\n",
    "last_agent_test[\"is_windows\"] = last_agent_test[\"userAgent\"].str.contains(\"Windows\", case=False, na=False).astype(int)\n",
    "last_agent_test[\"is_linux\"] = last_agent_test[\"userAgent\"].str.contains(\"Linux\", case=False, na=False).astype(int)\n",
    "last_agent_test[\"is_mobile\"] = last_agent_test[\"userAgent\"].str.contains(\"iPhone|iPad|Android|Mobile\", case=False, na=False).astype(int)\n",
    "\n",
    "last_agent_test[\"is_firefox\"] = last_agent_test[\"userAgent\"].str.contains(\"Firefox\", case=False, na=False).astype(int)\n",
    "last_agent_test[\"is_chrome\"] = last_agent_test[\"userAgent\"].str.contains(\"Chrome\", case=False, na=False).astype(int)\n",
    "\n",
    "tech_features_test = last_agent_test[[\"userId\", \"is_mac\", \"is_windows\", \"is_linux\", \"is_mobile\", \"is_firefox\", \"is_chrome\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce5da40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Fusion finale...\n",
      "üì• Mod√®le charg√©. Seuil optimal r√©cup√©r√© : 0.4300\n",
      "üìã Le mod√®le attend 21 colonnes.\n",
      "‚úÖ X_test pr√™t. Shape : (2904, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"üß© Fusion finale...\")\n",
    "\n",
    "# Fusion\n",
    "X_test = pd.DataFrame({\"userId\": test_users})\n",
    "X_test = X_test.merge(global_feats, on=\"userId\", how=\"left\")\n",
    "X_test = X_test.merge(behavior_df, on=\"userId\", how=\"left\")\n",
    "X_test = X_test.merge(trends[[\"userId\", \"trend_listening\"]], on=\"userId\", how=\"left\")\n",
    "X_test = X_test.merge(tech_features_test, on=\"userId\", how=\"left\")\n",
    "\n",
    "# Nettoyage\n",
    "X_test = X_test.fillna(0)\n",
    "userId_col = X_test[\"userId\"] # On garde les ID de c√¥t√© pour le fichier final\n",
    "X_test = X_test.drop(columns=[\"userId\", \"last_ts\", \"registration_ts\"]) # On enl√®ve ce qui n'est pas une feature\n",
    "\n",
    "# --- ALIGNEMENT DES COLONNES ---\n",
    "# On charge le mod√®le pour voir quelles colonnes il attend\n",
    "saved_data = joblib.load(MODEL_FILE)\n",
    "xgb_model = saved_data[\"model\"]\n",
    "best_threshold = saved_data[\"threshold\"]\n",
    "\n",
    "print(f\"üì• Mod√®le charg√©. Seuil optimal r√©cup√©r√© : {best_threshold:.4f}\")\n",
    "\n",
    "# On r√©cup√®re les noms des features du mod√®le\n",
    "expected_cols = xgb_model.get_booster().feature_names\n",
    "print(f\"üìã Le mod√®le attend {len(expected_cols)} colonnes.\")\n",
    "\n",
    "# On r√©organise X_test pour qu'il colle parfaitement (ajoute les colonnes manquantes avec 0, ignore les surplus)\n",
    "X_test = X_test.reindex(columns=expected_cols, fill_value=0)\n",
    "\n",
    "print(f\"‚úÖ X_test pr√™t. Shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6ae6c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ G√©n√©ration des pr√©dictions...\n",
      "üîß Test avec seuil manuel : 0.55\n",
      "Nouveau taux de churn pr√©dit : 41.15%\n",
      "‚úÖ Alignement avec example_submission.csv r√©ussi.\n",
      "\n",
      "üìä R√©sultat : 1195 churners d√©tect√©s sur 2904 utilisateurs.\n",
      "   Taux de churn pr√©dit : 41.15%\n",
      "üíæ Fichier sauvegard√© : submission_optimized.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÆ G√©n√©ration des pr√©dictions...\")\n",
    "\n",
    "# 1. Calcul des probabilit√©s\n",
    "probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 2. Application du SEUIL OPTIMAL (celui trouv√© dans notebook 02)\n",
    "#preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "MANUAL_THRESHOLD = 0.55 \n",
    "\n",
    "print(f\"üîß Test avec seuil manuel : {MANUAL_THRESHOLD}\")\n",
    "preds = (probs >= MANUAL_THRESHOLD).astype(int)\n",
    "\n",
    "# V√©rifie le taux avant de sauvegarder\n",
    "print(f\"Nouveau taux de churn pr√©dit : {preds.mean():.2%}\")\n",
    "\n",
    "# 3. Cr√©ation du fichier de soumission\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": userId_col,\n",
    "    \"target\": preds\n",
    "})\n",
    "\n",
    "# V√©rification du format avec l'exemple (si disponible)\n",
    "try:\n",
    "    example = pd.read_csv(EXAMPLE_PATH)\n",
    "    example[\"id\"] = example[\"id\"].astype(str)\n",
    "    submission[\"id\"] = submission[\"id\"].astype(str)\n",
    "    \n",
    "    # On garde seulement les IDs demand√©s dans l'exemple, dans le bon ordre\n",
    "    final_submission = example[[\"id\"]].merge(submission, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Remplir les √©ventuels trous par 0 (s√©curit√©)\n",
    "    final_submission[\"target\"] = final_submission[\"target\"].fillna(0).astype(int)\n",
    "    \n",
    "    print(\"‚úÖ Alignement avec example_submission.csv r√©ussi.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è example_submission.csv non trouv√©, on sauvegarde tel quel.\")\n",
    "    final_submission = submission\n",
    "\n",
    "# Stats\n",
    "n_churn = final_submission[\"target\"].sum()\n",
    "total = len(final_submission)\n",
    "print(f\"\\nüìä R√©sultat : {n_churn} churners d√©tect√©s sur {total} utilisateurs.\")\n",
    "print(f\"   Taux de churn pr√©dit : {n_churn/total:.2%}\")\n",
    "\n",
    "# Sauvegarde\n",
    "final_submission.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"üíæ Fichier sauvegard√© : {OUTPUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (conda)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
