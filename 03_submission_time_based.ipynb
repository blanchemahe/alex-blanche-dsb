{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b8a02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Chemins\n",
    "TEST_PATH = \"data/test.parquet\"\n",
    "EXAMPLE_PATH = \"data/example_submission.csv\"\n",
    "TRAIN_FEATS = \"train_features_multisnapshot.parquet\"\n",
    "#MODEL_FILE = \"xgb_final_optimized.pkl\"  # je viens de remplacer xgb_final_optimized.pkl\n",
    "MODEL_FILE = \"xgb_and_lgbm_final_optimized.pkl\"\n",
    "OUTPUT_FILE = \"submission_gridsearch_ensemble.csv\" # je viens de remplacer submission_optimized\n",
    "\n",
    "print(\"‚úÖ Configuration charg√©e.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25678fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Chargement du fichier Test...\n",
      "üìÖ Date de r√©f√©rence (T_test) : 2018-11-20 00:00:00\n",
      "üë• Utilisateurs √† pr√©dire : 2904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------\n",
    "# üì• Chargement des donn√©es test\n",
    "# -------------------------------------\n",
    "\n",
    "print(\"‚è≥ Chargement du fichier Test...\")\n",
    "test_df = pd.read_parquet(TEST_PATH)\n",
    "\n",
    "# Conversion timestamps\n",
    "test_df[\"ts\"] = pd.to_datetime(test_df[\"ts\"], unit=\"ms\")\n",
    "test_df[\"date\"] = test_df[\"ts\"].dt.date\n",
    "\n",
    "T_test = test_df[\"ts\"].max()\n",
    "print(f\"üìÖ Date de r√©f√©rence (T_test) : {T_test}\")\n",
    "\n",
    "test_users = test_df[\"userId\"].unique()\n",
    "print(f\"üë• Utilisateurs √† pr√©dire : {len(test_users)}\")\n",
    "\n",
    "# print(\"‚è≥ Chargement du fichier Test...\")\n",
    "# test_df = pd.read_parquet(TEST_PATH)\n",
    "\n",
    "# # Conversion des dates\n",
    "# test_df[\"ts\"] = pd.to_datetime(test_df[\"ts\"], unit=\"ms\")\n",
    "# test_df[\"date\"] = test_df[\"ts\"].dt.date\n",
    "\n",
    "# # La date \"actuelle\" pour le test est la derni√®re date du fichier\n",
    "# T_test = test_df[\"ts\"].max()\n",
    "# print(f\"üìÖ Date de r√©f√©rence (T_test) : {T_test}\")\n",
    "\n",
    "# # Liste des utilisateurs √† pr√©dire\n",
    "# test_users = test_df[\"userId\"].unique()\n",
    "# print(f\"üë• Utilisateurs √† pr√©dire : {len(test_users)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c91356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèóÔ∏è Reconstruction des features Globales...\n",
      "‚úÖ Global Features OK\n",
      "\n",
      "‚è±Ô∏è Construction des features de fen√™tres (7/14 jours)...\n",
      "\n",
      "üìä Reconstruction des features comportementales...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/wlt97vgx76x25gg48pgl0flh0000gn/T/ipykernel_98092/3459866378.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  behavior_df[\"satisfaction_ratio\"] = behavior_df[\"Thumbs Up\"] / (behavior_df[\"Thumbs Down\"] + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Behavioral Features OK\n",
      "\n",
      "üìà Reconstruction des trends...\n",
      "‚úÖ Trend Features OK\n",
      "\n",
      "üíª Extraction des features techniques...\n",
      "‚úÖ Device Features OK\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üèóÔ∏è RECONSTRUCTION DES FEATURES (identique au train)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüèóÔ∏è Reconstruction des features Globales...\")\n",
    "\n",
    "# -------- GLOBAL FEATURES --------\n",
    "global_feats = test_df.groupby(\"userId\").agg({\n",
    "    \"ts\": \"max\",\n",
    "    \"date\": \"nunique\",\n",
    "    \"sessionId\": \"nunique\",\n",
    "    \"length\": \"sum\",\n",
    "    \"registration\": \"min\"\n",
    "}).reset_index()\n",
    "\n",
    "global_feats.columns = [\"userId\", \"last_ts\", \"n_active_days\", \"n_sessions\", \"total_listening_time\", \"registration_ts\"]\n",
    "\n",
    "# Convert dates\n",
    "global_feats[\"registration_ts\"] = pd.to_datetime(global_feats[\"registration_ts\"], unit=\"ms\")\n",
    "\n",
    "# Derived features\n",
    "global_feats[\"recency_days\"] = (T_test - global_feats[\"last_ts\"]).dt.days\n",
    "global_feats[\"account_age_days\"] = (T_test - global_feats[\"registration_ts\"]).dt.days\n",
    "global_feats[\"avg_daily_listen\"] = global_feats[\"total_listening_time\"] / (global_feats[\"account_age_days\"] + 1)\n",
    "\n",
    "print(\"‚úÖ Global Features OK\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è Construction des features de fen√™tres (7/14 jours)...\")\n",
    "\n",
    "def build_window_stats_test(df_all, T_ref, window_days, suffix):\n",
    "    T_start = T_ref - pd.Timedelta(days=window_days)\n",
    "    win = df_all[df_all[\"ts\"] >= T_start]\n",
    "\n",
    "    if win.empty:\n",
    "        return pd.DataFrame({\"userId\": df_all[\"userId\"].unique()})\n",
    "\n",
    "    win_stats = win.groupby(\"userId\").agg({\n",
    "        \"length\": \"sum\",\n",
    "        \"sessionId\": \"nunique\",\n",
    "        \"date\": \"nunique\"\n",
    "    }).reset_index()\n",
    "\n",
    "    win_stats.columns = [\n",
    "        \"userId\",\n",
    "        f\"listen_time_{suffix}\",\n",
    "        f\"sessions_{suffix}\",\n",
    "        f\"active_days_{suffix}\"\n",
    "    ]\n",
    "    return win_stats\n",
    "\n",
    "win_7d  = build_window_stats_test(test_df, T_test, 7,  \"7d\")\n",
    "win_14d = build_window_stats_test(test_df, T_test, 14, \"14d\")\n",
    "\n",
    "windows_test = pd.DataFrame({\"userId\": test_users})\n",
    "for w in [win_7d, win_14d]:\n",
    "    windows_test = windows_test.merge(w, on=\"userId\", how=\"left\")\n",
    "\n",
    "windows_test = windows_test.fillna(0)\n",
    "\n",
    "# Ratios\n",
    "windows_test = windows_test.merge(\n",
    "    global_feats[[\"userId\", \"total_listening_time\"]],\n",
    "    on=\"userId\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "windows_test[\"ratio_listen_7d_14d\"] = windows_test[\"listen_time_7d\"] / (windows_test[\"listen_time_14d\"] + 1)\n",
    "windows_test[\"ratio_listen_7d_global\"] = windows_test[\"listen_time_7d\"] / (windows_test[\"total_listening_time\"] + 1)\n",
    "\n",
    "windows_test = windows_test.drop(columns=[\"total_listening_time\"])\n",
    "\n",
    "# -------- BEHAVIORAL FEATURES --------\n",
    "\n",
    "print(\"\\nüìä Reconstruction des features comportementales...\")\n",
    "\n",
    "page_counts = pd.pivot_table(\n",
    "    test_df, index=\"userId\", columns=\"page\", values=\"ts\",\n",
    "    aggfunc=\"count\", fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "useful_pages = [\"Thumbs Up\", \"Thumbs Down\", \"Roll Advert\", \"Error\", \"Upgrade\", \"Downgrade\", \"Add to Playlist\"]\n",
    "behavior_df = page_counts[[\"userId\"] + [p for p in useful_pages if p in page_counts.columns]]\n",
    "\n",
    "if \"Thumbs Up\" in behavior_df and \"Thumbs Down\" in behavior_df:\n",
    "    behavior_df[\"satisfaction_ratio\"] = behavior_df[\"Thumbs Up\"] / (behavior_df[\"Thumbs Down\"] + 1)\n",
    "\n",
    "print(\"‚úÖ Behavioral Features OK\")\n",
    "\n",
    "# -------- TREND FEATURES --------\n",
    "\n",
    "print(\"\\nüìà Reconstruction des trends...\")\n",
    "\n",
    "T_recent = T_test - pd.Timedelta(days=14)\n",
    "recent = test_df[test_df[\"ts\"] >= T_recent]\n",
    "\n",
    "recent_stats = (\n",
    "    recent.groupby(\"userId\")[\"length\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"length\": \"listen_time_recent\"})\n",
    ")\n",
    "\n",
    "trends = global_feats[[\"userId\", \"avg_daily_listen\"]].merge(recent_stats, on=\"userId\", how=\"left\").fillna(0)\n",
    "\n",
    "trends[\"avg_daily_listen_recent\"] = trends[\"listen_time_recent\"] / 14\n",
    "trends[\"trend_listening\"] = trends[\"avg_daily_listen_recent\"] / (trends[\"avg_daily_listen\"] + 0.01)\n",
    "\n",
    "print(\"‚úÖ Trend Features OK\")\n",
    "\n",
    "# -------- DEVICE FEATURES --------\n",
    "\n",
    "print(\"\\nüíª Extraction des features techniques...\")\n",
    "\n",
    "last_agent = test_df.sort_values(\"ts\").groupby(\"userId\")[\"userAgent\"].last().reset_index()\n",
    "\n",
    "def flag(pattern):\n",
    "    return last_agent[\"userAgent\"].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "last_agent[\"is_mac\"]     = flag(\"Macintosh\")\n",
    "last_agent[\"is_windows\"] = flag(\"Windows\")\n",
    "last_agent[\"is_linux\"]   = flag(\"Linux\")\n",
    "last_agent[\"is_mobile\"]  = flag(\"Mobile|iPhone|Android|iPad\")\n",
    "last_agent[\"is_firefox\"] = flag(\"Firefox\")\n",
    "last_agent[\"is_chrome\"]  = flag(\"Chrome\")\n",
    "\n",
    "tech_features = last_agent[[\"userId\",\"is_mac\",\"is_windows\",\"is_linux\",\"is_mobile\",\"is_firefox\",\"is_chrome\"]]\n",
    "\n",
    "print(\"‚úÖ Device Features OK\")\n",
    "\n",
    "\n",
    "\n",
    "# print(\"üèóÔ∏è Reconstruction des features (Globales + Comportement)...\")\n",
    "\n",
    "# # 1. Features Globales\n",
    "# global_feats = test_df.groupby(\"userId\").agg({\n",
    "#     \"ts\": \"max\",\n",
    "#     \"date\": \"nunique\",\n",
    "#     \"sessionId\": \"nunique\",\n",
    "#     \"length\": \"sum\",\n",
    "#     \"registration\": \"min\"\n",
    "# }).reset_index()\n",
    "\n",
    "# global_feats.columns = [\"userId\", \"last_ts\", \"n_active_days\", \"n_sessions\", \"total_listening_time\", \"registration_ts\"]\n",
    "\n",
    "# # Conversion et calculs\n",
    "# global_feats[\"registration_ts\"] = pd.to_datetime(global_feats[\"registration_ts\"], unit=\"ms\")\n",
    "# global_feats[\"recency_days\"] = (T_test - global_feats[\"last_ts\"]).dt.days\n",
    "# global_feats[\"account_age_days\"] = (T_test - global_feats[\"registration_ts\"]).dt.days\n",
    "# global_feats[\"avg_daily_listen\"] = global_feats[\"total_listening_time\"] / (global_feats[\"account_age_days\"] + 1)\n",
    "\n",
    "# # 2. Features Comportementales (Pouces, Erreurs...)\n",
    "# page_counts = pd.pivot_table(\n",
    "#     test_df, index=\"userId\", columns=\"page\", values=\"ts\", aggfunc=\"count\", fill_value=0\n",
    "# ).reset_index()\n",
    "\n",
    "# useful_pages = [\"Thumbs Up\", \"Thumbs Down\", \"Roll Advert\", \"Error\", \"Upgrade\", \"Downgrade\", \"Add to Playlist\"]\n",
    "# cols_to_keep = [\"userId\"] + [col for col in useful_pages if col in page_counts.columns]\n",
    "# behavior_df = page_counts[cols_to_keep].copy()\n",
    "\n",
    "# # Ratio de Satisfaction\n",
    "# if \"Thumbs Up\" in behavior_df and \"Thumbs Down\" in behavior_df:\n",
    "#     behavior_df[\"satisfaction_ratio\"] = behavior_df[\"Thumbs Up\"] / (behavior_df[\"Thumbs Down\"] + 1)\n",
    "\n",
    "# print(\"‚úÖ Features de base calcul√©es.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f08c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"üìà Reconstruction des features 'Trends'...\")\n",
    "\n",
    "# # 1. Fen√™tre r√©cente (14 jours avant la fin du test)\n",
    "# T_recent = T_test - pd.Timedelta(days=14)\n",
    "# test_recent = test_df[test_df[\"ts\"] >= T_recent]\n",
    "\n",
    "# # 2. Activit√© r√©cente\n",
    "# recent_stats = test_recent.groupby(\"userId\").agg({\n",
    "#     \"length\": \"sum\"\n",
    "# }).reset_index().rename(columns={\"length\": \"listen_time_recent\"})\n",
    "\n",
    "# # 3. Fusion et Calcul des Ratios\n",
    "# trends = global_feats[[\"userId\", \"avg_daily_listen\"]].merge(recent_stats, on=\"userId\", how=\"left\").fillna(0)\n",
    "\n",
    "# trends[\"avg_daily_listen_recent\"] = trends[\"listen_time_recent\"] / 14\n",
    "# trends[\"trend_listening\"] = trends[\"avg_daily_listen_recent\"] / (trends[\"avg_daily_listen\"] + 0.01)\n",
    "\n",
    "# print(\"‚úÖ Features Trends calcul√©es.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6c03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === A AJOUTER DANS NOTEBOOK 03 (Avant la fusion finale) ===\n",
    "# print(\"üíª Extraction des features techniques SUR LE TEST...\")\n",
    "\n",
    "# # Attention : on travaille sur test_df ici\n",
    "# last_agent_test = test_df.sort_values(\"ts\").groupby(\"userId\")[\"userAgent\"].last().reset_index()\n",
    "\n",
    "# last_agent_test[\"is_mac\"] = last_agent_test[\"userAgent\"].str.contains(\"Macintosh\", case=False, na=False).astype(int)\n",
    "# last_agent_test[\"is_windows\"] = last_agent_test[\"userAgent\"].str.contains(\"Windows\", case=False, na=False).astype(int)\n",
    "# last_agent_test[\"is_linux\"] = last_agent_test[\"userAgent\"].str.contains(\"Linux\", case=False, na=False).astype(int)\n",
    "# last_agent_test[\"is_mobile\"] = last_agent_test[\"userAgent\"].str.contains(\"iPhone|iPad|Android|Mobile\", case=False, na=False).astype(int)\n",
    "\n",
    "# last_agent_test[\"is_firefox\"] = last_agent_test[\"userAgent\"].str.contains(\"Firefox\", case=False, na=False).astype(int)\n",
    "# last_agent_test[\"is_chrome\"] = last_agent_test[\"userAgent\"].str.contains(\"Chrome\", case=False, na=False).astype(int)\n",
    "\n",
    "# tech_features_test = last_agent_test[[\"userId\", \"is_mac\", \"is_windows\", \"is_linux\", \"is_mobile\", \"is_firefox\", \"is_chrome\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5da40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Fusion finale...\n",
      "Shape apr√®s nettoyage datetime : (2904, 29)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üß© FUSION FINALE DES FEATURES\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüß© Fusion finale...\")\n",
    "\n",
    "X_test = pd.DataFrame({\"userId\": test_users})\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .merge(global_feats, on=\"userId\", how=\"left\")\n",
    "    .merge(behavior_df, on=\"userId\", how=\"left\")\n",
    "    .merge(trends[[\"userId\",\"trend_listening\"]], on=\"userId\", how=\"left\")\n",
    "    .merge(windows_test, on=\"userId\", how=\"left\")\n",
    "    .merge(tech_features, on=\"userId\", how=\"left\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Sauvegarde des userId pour la submission\n",
    "userId_col = X_test[\"userId\"]\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# ‚ùå SUPPRESSION des colonnes datetime\n",
    "# -------------------------\n",
    "cols_to_drop = [\"userId\", \"last_ts\", \"registration_ts\"]\n",
    "X_test = X_test.drop(columns=[c for c in cols_to_drop if c in X_test.columns])\n",
    "\n",
    "print(f\"Shape apr√®s nettoyage datetime : {X_test.shape}\")\n",
    "\n",
    "# print(\"üß© Fusion finale...\")\n",
    "\n",
    "# # Fusion\n",
    "# X_test = pd.DataFrame({\"userId\": test_users})\n",
    "# X_test = X_test.merge(global_feats, on=\"userId\", how=\"left\")\n",
    "# X_test = X_test.merge(behavior_df, on=\"userId\", how=\"left\")\n",
    "# X_test = X_test.merge(trends[[\"userId\", \"trend_listening\"]], on=\"userId\", how=\"left\")\n",
    "# X_test = X_test.merge(tech_features_test, on=\"userId\", how=\"left\")\n",
    "\n",
    "# # Nettoyage\n",
    "# X_test = X_test.fillna(0)\n",
    "# userId_col = X_test[\"userId\"] # On garde les ID de c√¥t√© pour le fichier final\n",
    "# X_test = X_test.drop(columns=[\"userId\", \"last_ts\", \"registration_ts\"]) # On enl√®ve ce qui n'est pas une feature\n",
    "\n",
    "# # --- ALIGNEMENT DES COLONNES ---\n",
    "# # On charge le mod√®le pour voir quelles colonnes il attend\n",
    "# saved_data = joblib.load(MODEL_FILE)\n",
    "# xgb_model = saved_data[\"model\"]\n",
    "# best_threshold = saved_data[\"threshold\"]\n",
    "\n",
    "# print(f\"üì• Mod√®le charg√©. Seuil optimal r√©cup√©r√© : {best_threshold:.4f}\")\n",
    "\n",
    "# # On r√©cup√®re les noms des features du mod√®le\n",
    "# expected_cols = xgb_model.get_booster().feature_names\n",
    "# print(f\"üìã Le mod√®le attend {len(expected_cols)} colonnes.\")\n",
    "\n",
    "# # On r√©organise X_test pour qu'il colle parfaitement (ajoute les colonnes manquantes avec 0, ignore les surplus)\n",
    "# X_test = X_test.reindex(columns=expected_cols, fill_value=0)\n",
    "\n",
    "# print(f\"‚úÖ X_test pr√™t. Shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87add427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Charg√© : XGB + LGBM params + ensemble_weight + ensemble_threshold\n",
      "üéöÔ∏è Poids ensemble (XGB) : 0.6\n",
      "üîß Seuil optimal         : 0.36000000000000004\n",
      "üì• Mod√®les XGB + params LGBM + seuil charg√©s.\n",
      "\n",
      "üåø Reconstruction LightGBM (train complet)...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3913, number of negative: 71950\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3234\n",
      "[LightGBM] [Info] Number of data points in the train set: 75863, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051580 -> initscore=-2.911667\n",
      "[LightGBM] [Info] Start training from score -2.911667\n",
      "üåø LightGBM reconstruit ‚úì\n"
     ]
    }
   ],
   "source": [
    "# CELLULE AJOUTER POUR TESTER L'ENSEMBLE\n",
    "\n",
    "# ==========================================\n",
    "# 3. CHARGEMENT DES MOD√àLES TRAIN√âS\n",
    "# ==========================================\n",
    "saved = joblib.load(MODEL_FILE)\n",
    "\n",
    "xgb_model       = saved[\"xgb_model\"]\n",
    "lgb_params      = saved[\"lgb_params\"]\n",
    "ensemble_weight = saved[\"ensemble_weight\"]\n",
    "best_threshold  = saved[\"ensemble_threshold\"]\n",
    "\n",
    "print(\"üì• Charg√© : XGB + LGBM params + ensemble_weight + ensemble_threshold\")\n",
    "print(f\"üéöÔ∏è Poids ensemble (XGB) : {ensemble_weight}\")\n",
    "print(f\"üîß Seuil optimal         : {best_threshold}\")\n",
    "\n",
    "print(\"üì• Mod√®les XGB + params LGBM + seuil charg√©s.\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. RECONSTRUCTION LGBM SUR LE TRAIN\n",
    "# ==========================================\n",
    "print(\"\\nüåø Reconstruction LightGBM (train complet)...\")\n",
    "\n",
    "train_df = pd.read_parquet(TRAIN_FEATS).sort_values(\"snapshot_time\")\n",
    "\n",
    "X_train_full = train_df.drop(columns=[\"userId\", \"target\"])\n",
    "X_train_full = X_train_full.drop(columns=[c for c in [\"last_ts\",\"registration_ts\",\"snapshot_time\"] if c in X_train_full])\n",
    "y_train_full = train_df[\"target\"]\n",
    "\n",
    "# alignement des colonnes avec XGB\n",
    "X_train_full = X_train_full.reindex(columns=xgb_model.get_booster().feature_names, fill_value=0)\n",
    "X_test = X_test.reindex(columns=xgb_model.get_booster().feature_names, fill_value=0)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "lgb_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"üåø LightGBM reconstruit ‚úì\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ae6c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ G√©n√©ration des pr√©dictions (XGB + LGBM + Ensemble)...\n",
      "üìä Taux de churn pr√©dit (ensemble) : 43.73%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîÆ PREDICTION\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nüîÆ G√©n√©ration des pr√©dictions (XGB + LGBM + Ensemble)...\")\n",
    "\n",
    "proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "proba_lgb = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "probs = ensemble_weight * proba_xgb + (1 - ensemble_weight) * proba_lgb\n",
    "\n",
    "preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"üìä Taux de churn pr√©dit (ensemble) : {preds.mean():.2%}\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": userId_col,\n",
    "    \"target\": preds\n",
    "})\n",
    "\n",
    "\n",
    "#8 lignes suivantes ont √©t√© remplace par les derni√®res lignes pour le test de l'ensemble\n",
    "# print(\"\\nüîÆ G√©n√©ration des pr√©dictions...\")\n",
    "\n",
    "# probs = model.predict_proba(X_test)[:, 1]\n",
    "# preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "# print(f\"üìä Taux de churn pr√©dit : {preds.mean():.2%}\")\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": userId_col,\n",
    "#     \"target\": preds\n",
    "# })\n",
    "\n",
    "\n",
    "\n",
    "# print(\"üîÆ G√©n√©ration des pr√©dictions...\")\n",
    "\n",
    "# # 1. Calcul des probabilit√©s\n",
    "# probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # 2. Application du SEUIL OPTIMAL (celui trouv√© dans notebook 02)\n",
    "# #preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "# MANUAL_THRESHOLD = 0.55 \n",
    "\n",
    "# print(f\"üîß Test avec seuil manuel : {MANUAL_THRESHOLD}\")\n",
    "# preds = (probs >= MANUAL_THRESHOLD).astype(int)\n",
    "\n",
    "# # V√©rifie le taux avant de sauvegarder\n",
    "# print(f\"Nouveau taux de churn pr√©dit : {preds.mean():.2%}\")\n",
    "\n",
    "# # 3. Cr√©ation du fichier de soumission\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": userId_col,\n",
    "#     \"target\": preds\n",
    "# })\n",
    "\n",
    "# # V√©rification du format avec l'exemple (si disponible)\n",
    "# try:\n",
    "#     example = pd.read_csv(EXAMPLE_PATH)\n",
    "#     example[\"id\"] = example[\"id\"].astype(str)\n",
    "#     submission[\"id\"] = submission[\"id\"].astype(str)\n",
    "    \n",
    "#     # On garde seulement les IDs demand√©s dans l'exemple, dans le bon ordre\n",
    "#     final_submission = example[[\"id\"]].merge(submission, on=\"id\", how=\"left\")\n",
    "    \n",
    "#     # Remplir les √©ventuels trous par 0 (s√©curit√©)\n",
    "#     final_submission[\"target\"] = final_submission[\"target\"].fillna(0).astype(int)\n",
    "    \n",
    "#     print(\"‚úÖ Alignement avec example_submission.csv r√©ussi.\")\n",
    "# except FileNotFoundError:\n",
    "#     print(\"‚ö†Ô∏è example_submission.csv non trouv√©, on sauvegarde tel quel.\")\n",
    "#     final_submission = submission\n",
    "\n",
    "# # Stats\n",
    "# n_churn = final_submission[\"target\"].sum()\n",
    "# total = len(final_submission)\n",
    "# print(f\"\\nüìä R√©sultat : {n_churn} churners d√©tect√©s sur {total} utilisateurs.\")\n",
    "# print(f\"   Taux de churn pr√©dit : {n_churn/total:.2%}\")\n",
    "\n",
    "# # Sauvegarde\n",
    "# final_submission.to_csv(OUTPUT_FILE, index=False)\n",
    "# print(f\"üíæ Fichier sauvegard√© : {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce8f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Alignement avec example_submission.csv r√©ussi.\n",
      "\n",
      "üíæ Fichier final sauvegard√© : submission_gridsearch_ensemble.csv\n",
      "üéâ Submission pr√™te !\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üì§ ALIGNEMENT AVEC example_submission.csv\n",
    "# ============================================================\n",
    "\n",
    "try:\n",
    "    example = pd.read_csv(EXAMPLE_PATH)\n",
    "    example[\"id\"] = example[\"id\"].astype(str)\n",
    "    \n",
    "    final_submission = example[[\"id\"]].merge(\n",
    "        submission.assign(id=submission[\"id\"].astype(str)),\n",
    "        on=\"id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    final_submission[\"target\"] = final_submission[\"target\"].fillna(0).astype(int)\n",
    "    print(\"‚úÖ Alignement avec example_submission.csv r√©ussi.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Pas d'exemple trouv√© ‚Üí fichier envoy√© tel quel.\")\n",
    "    final_submission = submission\n",
    "\n",
    "# ============================================================\n",
    "# üíæ SAUVEGARDE\n",
    "# ============================================================\n",
    "\n",
    "final_submission.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nüíæ Fichier final sauvegard√© : {OUTPUT_FILE}\")\n",
    "print(\"üéâ Submission pr√™te !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
