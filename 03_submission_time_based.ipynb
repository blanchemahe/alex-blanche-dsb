{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b8a02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Chemins\n",
    "TEST_PATH = \"data/test.parquet\"\n",
    "EXAMPLE_PATH = \"data/example_submission.csv\"\n",
    "MODEL_FILE = \"xgb_final_optimized.pkl\"\n",
    "OUTPUT_FILE = \"submission_xgb_gridsearch.csv\" \n",
    "\n",
    "print(\"‚úÖ Configuration charg√©e.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25678fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Chargement du fichier Test...\n",
      "üìÖ Date de r√©f√©rence (T_test) : 2018-11-20 00:00:00\n",
      "üë• Utilisateurs √† pr√©dire : 2904\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# üì• Chargement des donn√©es test\n",
    "# -------------------------------------\n",
    "\n",
    "print(\"‚è≥ Chargement du fichier Test...\")\n",
    "test_df = pd.read_parquet(TEST_PATH)\n",
    "\n",
    "# Conversion timestamps\n",
    "test_df[\"ts\"] = pd.to_datetime(test_df[\"ts\"], unit=\"ms\")\n",
    "test_df[\"date\"] = test_df[\"ts\"].dt.date\n",
    "\n",
    "T_test = test_df[\"ts\"].max()\n",
    "print(f\"üìÖ Date de r√©f√©rence (T_test) : {T_test}\")\n",
    "\n",
    "test_users = test_df[\"userId\"].unique()\n",
    "print(f\"üë• Utilisateurs √† pr√©dire : {len(test_users)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c91356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèóÔ∏è Reconstruction des features Globales...\n",
      "‚úÖ Global Features OK\n",
      "\n",
      "‚è±Ô∏è Construction des features de fen√™tres (7/14 jours)...\n",
      "\n",
      "üìä Reconstruction des features comportementales...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/wlt97vgx76x25gg48pgl0flh0000gn/T/ipykernel_99305/2161045420.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  behavior_df[\"satisfaction_ratio\"] = behavior_df[\"Thumbs Up\"] / (behavior_df[\"Thumbs Down\"] + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Behavioral Features OK\n",
      "\n",
      "üìà Reconstruction des trends...\n",
      "‚úÖ Trend Features OK\n",
      "\n",
      "üíª Extraction des features techniques...\n",
      "‚úÖ Device Features OK\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üèóÔ∏è RECONSTRUCTION DES FEATURES (identique au train)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüèóÔ∏è Reconstruction des features Globales...\")\n",
    "\n",
    "# -------- GLOBAL FEATURES --------\n",
    "global_feats = test_df.groupby(\"userId\").agg({\n",
    "    \"ts\": \"max\",\n",
    "    \"date\": \"nunique\",\n",
    "    \"sessionId\": \"nunique\",\n",
    "    \"length\": \"sum\",\n",
    "    \"registration\": \"min\"\n",
    "}).reset_index()\n",
    "\n",
    "global_feats.columns = [\"userId\", \"last_ts\", \"n_active_days\", \"n_sessions\", \"total_listening_time\", \"registration_ts\"]\n",
    "\n",
    "# Convert dates\n",
    "global_feats[\"registration_ts\"] = pd.to_datetime(global_feats[\"registration_ts\"], unit=\"ms\")\n",
    "\n",
    "# Derived features\n",
    "global_feats[\"recency_days\"] = (T_test - global_feats[\"last_ts\"]).dt.days\n",
    "global_feats[\"account_age_days\"] = (T_test - global_feats[\"registration_ts\"]).dt.days\n",
    "global_feats[\"avg_daily_listen\"] = global_feats[\"total_listening_time\"] / (global_feats[\"account_age_days\"] + 1)\n",
    "\n",
    "print(\"‚úÖ Global Features OK\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è Construction des features de fen√™tres (7/14 jours)...\")\n",
    "\n",
    "def build_window_stats_test(df_all, T_ref, window_days, suffix):\n",
    "    T_start = T_ref - pd.Timedelta(days=window_days)\n",
    "    win = df_all[df_all[\"ts\"] >= T_start]\n",
    "\n",
    "    if win.empty:\n",
    "        return pd.DataFrame({\"userId\": df_all[\"userId\"].unique()})\n",
    "\n",
    "    win_stats = win.groupby(\"userId\").agg({\n",
    "        \"length\": \"sum\",\n",
    "        \"sessionId\": \"nunique\",\n",
    "        \"date\": \"nunique\"\n",
    "    }).reset_index()\n",
    "\n",
    "    win_stats.columns = [\n",
    "        \"userId\",\n",
    "        f\"listen_time_{suffix}\",\n",
    "        f\"sessions_{suffix}\",\n",
    "        f\"active_days_{suffix}\"\n",
    "    ]\n",
    "    return win_stats\n",
    "\n",
    "win_7d  = build_window_stats_test(test_df, T_test, 7,  \"7d\")\n",
    "win_14d = build_window_stats_test(test_df, T_test, 14, \"14d\")\n",
    "\n",
    "windows_test = pd.DataFrame({\"userId\": test_users})\n",
    "for w in [win_7d, win_14d]:\n",
    "    windows_test = windows_test.merge(w, on=\"userId\", how=\"left\")\n",
    "\n",
    "windows_test = windows_test.fillna(0)\n",
    "\n",
    "# Ratios\n",
    "windows_test = windows_test.merge(\n",
    "    global_feats[[\"userId\", \"total_listening_time\"]],\n",
    "    on=\"userId\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "windows_test[\"ratio_listen_7d_14d\"] = windows_test[\"listen_time_7d\"] / (windows_test[\"listen_time_14d\"] + 1)\n",
    "windows_test[\"ratio_listen_7d_global\"] = windows_test[\"listen_time_7d\"] / (windows_test[\"total_listening_time\"] + 1)\n",
    "\n",
    "windows_test = windows_test.drop(columns=[\"total_listening_time\"])\n",
    "\n",
    "# -------- BEHAVIORAL FEATURES --------\n",
    "\n",
    "print(\"\\nüìä Reconstruction des features comportementales...\")\n",
    "\n",
    "page_counts = pd.pivot_table(\n",
    "    test_df, index=\"userId\", columns=\"page\", values=\"ts\",\n",
    "    aggfunc=\"count\", fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "useful_pages = [\"Thumbs Up\", \"Thumbs Down\", \"Roll Advert\", \"Error\", \"Upgrade\", \"Downgrade\", \"Add to Playlist\"]\n",
    "behavior_df = page_counts[[\"userId\"] + [p for p in useful_pages if p in page_counts.columns]]\n",
    "\n",
    "if \"Thumbs Up\" in behavior_df and \"Thumbs Down\" in behavior_df:\n",
    "    behavior_df[\"satisfaction_ratio\"] = behavior_df[\"Thumbs Up\"] / (behavior_df[\"Thumbs Down\"] + 1)\n",
    "\n",
    "print(\"‚úÖ Behavioral Features OK\")\n",
    "\n",
    "# -------- TREND FEATURES --------\n",
    "\n",
    "print(\"\\nüìà Reconstruction des trends...\")\n",
    "\n",
    "T_recent = T_test - pd.Timedelta(days=14)\n",
    "recent = test_df[test_df[\"ts\"] >= T_recent]\n",
    "\n",
    "recent_stats = (\n",
    "    recent.groupby(\"userId\")[\"length\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"length\": \"listen_time_recent\"})\n",
    ")\n",
    "\n",
    "trends = global_feats[[\"userId\", \"avg_daily_listen\"]].merge(recent_stats, on=\"userId\", how=\"left\").fillna(0)\n",
    "\n",
    "trends[\"avg_daily_listen_recent\"] = trends[\"listen_time_recent\"] / 14\n",
    "trends[\"trend_listening\"] = trends[\"avg_daily_listen_recent\"] / (trends[\"avg_daily_listen\"] + 0.01)\n",
    "\n",
    "print(\"‚úÖ Trend Features OK\")\n",
    "\n",
    "# -------- DEVICE FEATURES --------\n",
    "\n",
    "print(\"\\nüíª Extraction des features techniques...\")\n",
    "\n",
    "last_agent = test_df.sort_values(\"ts\").groupby(\"userId\")[\"userAgent\"].last().reset_index()\n",
    "\n",
    "def flag(pattern):\n",
    "    return last_agent[\"userAgent\"].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "last_agent[\"is_mac\"]     = flag(\"Macintosh\")\n",
    "last_agent[\"is_windows\"] = flag(\"Windows\")\n",
    "last_agent[\"is_linux\"]   = flag(\"Linux\")\n",
    "last_agent[\"is_mobile\"]  = flag(\"Mobile|iPhone|Android|iPad\")\n",
    "last_agent[\"is_firefox\"] = flag(\"Firefox\")\n",
    "last_agent[\"is_chrome\"]  = flag(\"Chrome\")\n",
    "\n",
    "tech_features = last_agent[[\"userId\",\"is_mac\",\"is_windows\",\"is_linux\",\"is_mobile\",\"is_firefox\",\"is_chrome\"]]\n",
    "\n",
    "print(\"‚úÖ Device Features OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5da40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Fusion finale...\n",
      "Shape X_test apr√®s nettoyage datetime : (2904, 29)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üß© FUSION FINALE DES FEATURES\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüß© Fusion finale...\")\n",
    "\n",
    "X_test = pd.DataFrame({\"userId\": test_users})\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .merge(global_feats, on=\"userId\", how=\"left\")\n",
    "    .merge(behavior_df, on=\"userId\", how=\"left\")\n",
    "    .merge(trends[[\"userId\",\"trend_listening\"]], on=\"userId\", how=\"left\")\n",
    "    .merge(windows_test, on=\"userId\", how=\"left\")\n",
    "    .merge(tech_features, on=\"userId\", how=\"left\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Sauvegarde des userId pour la submission\n",
    "userId_col = X_test[\"userId\"]\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# ‚ùå SUPPRESSION des colonnes datetime\n",
    "# -------------------------\n",
    "cols_to_drop = [\"userId\", \"last_ts\", \"registration_ts\"]\n",
    "X_test = X_test.drop(columns=[c for c in cols_to_drop if c in X_test.columns])\n",
    "\n",
    "print(f\"Shape X_test apr√®s nettoyage datetime : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87add427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Chargement mod√®le XGBoost...\n",
      "üî• Seuil utilis√© : 0.50\n",
      "üìê Colonnes align√©es avec le mod√®le.\n",
      "X_test final : (2904, 29)\n"
     ]
    }
   ],
   "source": [
    "# CELLULE AJOUTER POUR TESTER L'ENSEMBLE\n",
    "\n",
    "# -------------------------------------\n",
    "# 3. Chargement mod√®le XGB\n",
    "# -------------------------------------\n",
    "print(\"\\nüì• Chargement mod√®le XGBoost...\")\n",
    "\n",
    "model = joblib.load(MODEL_FILE)\n",
    "best_threshold = 0.5  # ou autre seuil si tu en as un\n",
    "\n",
    "print(f\"üî• Seuil utilis√© : {best_threshold:.2f}\")\n",
    "\n",
    "# Alignement colonnes\n",
    "expected_cols = model.get_booster().feature_names\n",
    "X_test = X_test.reindex(columns=expected_cols, fill_value=0)\n",
    "\n",
    "print(\"üìê Colonnes align√©es avec le mod√®le.\")\n",
    "print(\"X_test final :\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ae6c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ G√©n√©ration des pr√©dictions...\n",
      "üìä Taux de churn pr√©dit : 53.24%\n",
      "üìä Taux de churn pr√©dit : 53.24%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîÆ PREDICTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüîÆ G√©n√©ration des pr√©dictions...\")\n",
    "\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"üìä Taux de churn pr√©dit : {preds.mean():.2%}\")\n",
    "\n",
    "preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"üìä Taux de churn pr√©dit : {preds.mean():.2%}\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": userId_col,\n",
    "    \"target\": preds\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# print(\"üîÆ G√©n√©ration des pr√©dictions...\")\n",
    "\n",
    "# # 1. Calcul des probabilit√©s\n",
    "# probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # 2. Application du SEUIL OPTIMAL (celui trouv√© dans notebook 02)\n",
    "# #preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "# MANUAL_THRESHOLD = 0.55 \n",
    "\n",
    "# print(f\"üîß Test avec seuil manuel : {MANUAL_THRESHOLD}\")\n",
    "# preds = (probs >= MANUAL_THRESHOLD).astype(int)\n",
    "\n",
    "# # V√©rifie le taux avant de sauvegarder\n",
    "# print(f\"Nouveau taux de churn pr√©dit : {preds.mean():.2%}\")\n",
    "\n",
    "# # 3. Cr√©ation du fichier de soumission\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": userId_col,\n",
    "#     \"target\": preds\n",
    "# })\n",
    "\n",
    "# # V√©rification du format avec l'exemple (si disponible)\n",
    "# try:\n",
    "#     example = pd.read_csv(EXAMPLE_PATH)\n",
    "#     example[\"id\"] = example[\"id\"].astype(str)\n",
    "#     submission[\"id\"] = submission[\"id\"].astype(str)\n",
    "    \n",
    "#     # On garde seulement les IDs demand√©s dans l'exemple, dans le bon ordre\n",
    "#     final_submission = example[[\"id\"]].merge(submission, on=\"id\", how=\"left\")\n",
    "    \n",
    "#     # Remplir les √©ventuels trous par 0 (s√©curit√©)\n",
    "#     final_submission[\"target\"] = final_submission[\"target\"].fillna(0).astype(int)\n",
    "    \n",
    "#     print(\"‚úÖ Alignement avec example_submission.csv r√©ussi.\")\n",
    "# except FileNotFoundError:\n",
    "#     print(\"‚ö†Ô∏è example_submission.csv non trouv√©, on sauvegarde tel quel.\")\n",
    "#     final_submission = submission\n",
    "\n",
    "# # Stats\n",
    "# n_churn = final_submission[\"target\"].sum()\n",
    "# total = len(final_submission)\n",
    "# print(f\"\\nüìä R√©sultat : {n_churn} churners d√©tect√©s sur {total} utilisateurs.\")\n",
    "# print(f\"   Taux de churn pr√©dit : {n_churn/total:.2%}\")\n",
    "\n",
    "# # Sauvegarde\n",
    "# final_submission.to_csv(OUTPUT_FILE, index=False)\n",
    "# print(f\"üíæ Fichier sauvegard√© : {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce8f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Alignement avec example_submission.csv r√©ussi.\n",
      "\n",
      "üíæ Fichier final sauvegard√© : submission_xgb_gridsearch.csv\n",
      "üéâ Submission pr√™te (XGB only) !\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üì§ ALIGNEMENT AVEC example_submission.csv\n",
    "# ============================================================\n",
    "\n",
    "try:\n",
    "    example = pd.read_csv(EXAMPLE_PATH)\n",
    "    example[\"id\"] = example[\"id\"].astype(str)\n",
    "    \n",
    "    final_submission = example[[\"id\"]].merge(\n",
    "        submission.assign(id=submission[\"id\"].astype(str)),\n",
    "        on=\"id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    final_submission[\"target\"] = final_submission[\"target\"].fillna(0).astype(int)\n",
    "    print(\"‚úÖ Alignement avec example_submission.csv r√©ussi.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Pas d'exemple trouv√© ‚Üí fichier envoy√© tel quel.\")\n",
    "    final_submission = submission\n",
    "\n",
    "# ============================================================\n",
    "# üíæ SAUVEGARDE\n",
    "# ============================================================\n",
    "\n",
    "final_submission.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nüíæ Fichier final sauvegard√© : {OUTPUT_FILE}\")\n",
    "print(\"üéâ Submission pr√™te (XGB only) !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
