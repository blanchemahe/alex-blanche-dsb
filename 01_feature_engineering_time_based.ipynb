{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d48262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# On ignore les messages rouges non critiques\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TRAIN_PATH = \"data/train.parquet\"\n",
    "OUTPUT_PATH = \"train_features_multisnapshot.parquet\"\n",
    "\n",
    "# T0 : La date de coupure. On regarde l'historique AVANT cette date.\n",
    "T0 = pd.Timestamp(\"2018-11-10\") \n",
    "HORIZON_DAYS = 10 # On cherche √† pr√©dire le churn dans les 10 jours qui suivent\n",
    "\n",
    "print(\"‚úÖ Configuration charg√©e.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1528631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Chargement du fichier train...\n",
      "üìä Dimensions du dataset : (17499636, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>gender</th>\n",
       "      <th>firstName</th>\n",
       "      <th>level</th>\n",
       "      <th>lastName</th>\n",
       "      <th>userId</th>\n",
       "      <th>ts</th>\n",
       "      <th>auth</th>\n",
       "      <th>page</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>location</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>method</th>\n",
       "      <th>length</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>time</th>\n",
       "      <th>registration</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>M</td>\n",
       "      <td>Shlok</td>\n",
       "      <td>paid</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1749042</td>\n",
       "      <td>2018-10-01 00:00:01</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>278</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>PUT</td>\n",
       "      <td>524.32934</td>\n",
       "      <td>Ich mache einen Spiegel - Dream Part 4</td>\n",
       "      <td>Popol Vuh</td>\n",
       "      <td>2018-10-01 00:00:01</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "      <td>2018-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>200</td>\n",
       "      <td>M</td>\n",
       "      <td>Shlok</td>\n",
       "      <td>paid</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1749042</td>\n",
       "      <td>2018-10-01 00:08:45</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>279</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>PUT</td>\n",
       "      <td>178.02404</td>\n",
       "      <td>Monster (Album Version)</td>\n",
       "      <td>Skillet</td>\n",
       "      <td>2018-10-01 00:08:45</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "      <td>2018-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>200</td>\n",
       "      <td>M</td>\n",
       "      <td>Shlok</td>\n",
       "      <td>paid</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1749042</td>\n",
       "      <td>2018-10-01 00:11:43</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>280</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>PUT</td>\n",
       "      <td>232.61995</td>\n",
       "      <td>Seven Nation Army</td>\n",
       "      <td>The White Stripes</td>\n",
       "      <td>2018-10-01 00:11:43</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "      <td>2018-10-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      status gender firstName level lastName   userId                  ts  \\\n",
       "0        200      M     Shlok  paid  Johnson  1749042 2018-10-01 00:00:01   \n",
       "992      200      M     Shlok  paid  Johnson  1749042 2018-10-01 00:08:45   \n",
       "1360     200      M     Shlok  paid  Johnson  1749042 2018-10-01 00:11:43   \n",
       "\n",
       "           auth      page  sessionId                         location  \\\n",
       "0     Logged In  NextSong      22683  Dallas-Fort Worth-Arlington, TX   \n",
       "992   Logged In  NextSong      22683  Dallas-Fort Worth-Arlington, TX   \n",
       "1360  Logged In  NextSong      22683  Dallas-Fort Worth-Arlington, TX   \n",
       "\n",
       "      itemInSession                                          userAgent method  \\\n",
       "0               278  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...    PUT   \n",
       "992             279  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...    PUT   \n",
       "1360            280  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...    PUT   \n",
       "\n",
       "         length                                    song             artist  \\\n",
       "0     524.32934  Ich mache einen Spiegel - Dream Part 4          Popol Vuh   \n",
       "992   178.02404                 Monster (Album Version)            Skillet   \n",
       "1360  232.61995                       Seven Nation Army  The White Stripes   \n",
       "\n",
       "                    time        registration        date  \n",
       "0    2018-10-01 00:00:01 2018-08-08 13:22:21  2018-10-01  \n",
       "992  2018-10-01 00:08:45 2018-08-08 13:22:21  2018-10-01  \n",
       "1360 2018-10-01 00:11:43 2018-08-08 13:22:21  2018-10-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"‚è≥ Chargement du fichier train...\")\n",
    "\n",
    "df = pd.read_parquet(\"data/train.parquet\")\n",
    "\n",
    "# Conversion des dates (millisecondes -> datetime)\n",
    "df[\"ts\"] = pd.to_datetime(df[\"ts\"], unit=\"ms\")\n",
    "df[\"date\"] = df[\"ts\"].dt.date\n",
    "\n",
    "print(f\"üìä Dimensions du dataset : {df.shape}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0ddde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è D√©coupage temporel (Observation vs Futur)...\n",
      "2018-10-01 00:00:01 2018-11-20 00:00:00\n",
      "T0 utilis√©s :\n",
      "DatetimeIndex(['2018-10-11 00:00:01', '2018-10-18 00:00:01',\n",
      "               '2018-10-25 00:00:01', '2018-11-01 00:00:01',\n",
      "               '2018-11-08 00:00:01'],\n",
      "              dtype='datetime64[ns]', freq='7D')\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÇÔ∏è D√©coupage temporel (Observation vs Futur)...\")\n",
    "df[\"ts\"] = pd.to_datetime(df[\"ts\"], unit=\"ms\")\n",
    "\n",
    "min_ts = df[\"ts\"].min()\n",
    "max_ts = df[\"ts\"].max()\n",
    "\n",
    "print(min_ts, max_ts)\n",
    "\n",
    "BUFFER_DAYS = 10\n",
    "HORIZON_DAYS = 10  # ou ta valeur r√©elle\n",
    "\n",
    "start_T0 = min_ts + pd.Timedelta(days=BUFFER_DAYS)\n",
    "end_T0   = max_ts - pd.Timedelta(days=HORIZON_DAYS)\n",
    "\n",
    "T0_list = pd.date_range(start=start_T0, end=end_T0, freq=\"7D\")\n",
    "\n",
    "print(\"T0 utilis√©s :\")\n",
    "print(T0_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312c8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset: (17499636, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw dataset: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77aa854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== snapshot T0 = 2018-10-11 ====\n",
      "\n",
      "==== snapshot T0 = 2018-10-18 ====\n",
      "\n",
      "==== snapshot T0 = 2018-10-25 ====\n",
      "\n",
      "==== snapshot T0 = 2018-11-01 ====\n",
      "\n",
      "==== snapshot T0 = 2018-11-08 ====\n",
      "\n",
      "üéâ Dataset multi-snapshot sauvegard√© dans train_features_multisnapshot.parquet\n",
      "Final shape = (75863, 34)\n"
     ]
    }
   ],
   "source": [
    "WINDOW_RECENT = 14\n",
    "\n",
    "def compute_snapshot(df, T0):\n",
    "    T0 = pd.Timestamp(T0)\n",
    "    print(f\"\\n==== snapshot T0 = {T0.date()} ====\")\n",
    "\n",
    "    # historique\n",
    "    obs = df[df[\"ts\"] <= T0].copy()\n",
    "\n",
    "    # futur (pour label)\n",
    "    future = df[(df[\"ts\"] > T0) & (df[\"ts\"] <= T0 + pd.Timedelta(days=HORIZON_DAYS))]\n",
    "\n",
    "    # utilisateurs ayant d√©j√† churn avant T0 ‚Üí exclus\n",
    "    past_churners = obs[obs[\"page\"] == \"Cancellation Confirmation\"][\"userId\"].unique()\n",
    "    obs_clean = obs[~obs[\"userId\"].isin(past_churners)]\n",
    "\n",
    "    users = obs_clean[\"userId\"].unique()\n",
    "\n",
    "    # ---- CIBLE (target = churn dans les 10 jours) ----\n",
    "    churn_future = future[future[\"page\"] == \"Cancellation Confirmation\"][\"userId\"].unique()\n",
    "    target_df = pd.DataFrame({\"userId\": users})\n",
    "    target_df[\"target\"] = target_df[\"userId\"].isin(churn_future).astype(int)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 1. Global features\n",
    "    # ----------------------------------------\n",
    "    global_feats = obs_clean.groupby(\"userId\").agg({\n",
    "        \"ts\": \"max\",\n",
    "        \"date\": \"nunique\",\n",
    "        \"sessionId\": \"nunique\",\n",
    "        \"length\": \"sum\",\n",
    "        \"registration\": \"min\"\n",
    "    }).reset_index()\n",
    "\n",
    "    global_feats.columns = [\n",
    "        \"userId\", \"last_ts\", \"n_active_days\", \n",
    "        \"n_sessions\", \"total_listening_time\", \"registration_ts\"\n",
    "    ]\n",
    "\n",
    "    global_feats[\"registration_ts\"] = pd.to_datetime(global_feats[\"registration_ts\"], unit=\"ms\")\n",
    "    global_feats[\"recency_days\"] = (T0 - global_feats[\"last_ts\"]).dt.days\n",
    "    global_feats[\"account_age_days\"] = (T0 - global_feats[\"registration_ts\"]).dt.days\n",
    "    global_feats[\"avg_daily_listen\"] = global_feats[\"total_listening_time\"] / (global_feats[\"account_age_days\"] + 1)\n",
    "\n",
    "    # 1.1 ---------- ajout de WINDOW FEATURES (7 / 14 jours) ----------\n",
    "    def build_window_stats(obs_base, T0, window_days, suffix):\n",
    "        \"\"\"Calcule des stats sur une fen√™tre glissante avant T0.\"\"\"\n",
    "        T_start = T0 - pd.Timedelta(days=window_days)\n",
    "        win = obs_base[obs_base[\"ts\"] >= T_start]\n",
    "\n",
    "        if win.empty:\n",
    "            # Aucun log dans la fen√™tre ‚Üí on renvoie un DF vide avec juste userId\n",
    "            return pd.DataFrame({\"userId\": obs_base[\"userId\"].unique()})\n",
    "\n",
    "        # Stats de base sur la fen√™tre\n",
    "        win_stats = win.groupby(\"userId\").agg({\n",
    "            \"length\": \"sum\",\n",
    "            \"sessionId\": \"nunique\",\n",
    "            \"date\": \"nunique\"\n",
    "        }).reset_index()\n",
    "\n",
    "        win_stats.columns = [\n",
    "            \"userId\",\n",
    "            f\"listen_time_{suffix}\",\n",
    "            f\"sessions_{suffix}\",\n",
    "            f\"active_days_{suffix}\"\n",
    "        ]\n",
    "        return win_stats\n",
    "\n",
    "    # Fen√™tres 7, 14, 30 jours\n",
    "    win_7d  = build_window_stats(obs_clean, T0, 7,  \"7d\")\n",
    "    win_14d = build_window_stats(obs_clean, T0, 14, \"14d\")\n",
    "\n",
    "    # Fusion des fen√™tres\n",
    "    windows_df = pd.DataFrame({\"userId\": obs_clean[\"userId\"].unique()})\n",
    "    for w in [win_7d, win_14d]:\n",
    "        windows_df = windows_df.merge(w, on=\"userId\", how=\"left\")\n",
    "\n",
    "    # Remplissage des NaN par 0 (aucune activit√© dans la fen√™tre)\n",
    "    windows_df = windows_df.fillna(0)\n",
    "\n",
    "    # Ratios int√©ressants\n",
    "    # 1) 7j vs 14j\n",
    "    windows_df[\"ratio_listen_7d_14d\"] = windows_df[\"listen_time_7d\"] / (windows_df[\"listen_time_14d\"] + 1)\n",
    "\n",
    "    # 2) 7j vs global\n",
    "    windows_df = windows_df.merge(\n",
    "        global_feats[[\"userId\", \"total_listening_time\"]],\n",
    "        on=\"userId\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    windows_df[\"ratio_listen_7d_global\"] = windows_df[\"listen_time_7d\"] / (windows_df[\"total_listening_time\"] + 1)\n",
    "\n",
    "    # On peut maintenant retirer total_listening_time de windows_df (d√©j√† pr√©sent dans global_feats)\n",
    "    windows_df = windows_df.drop(columns=[\"total_listening_time\"])\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 2. Behavioral features\n",
    "    # ----------------------------------------\n",
    "    page_counts = pd.pivot_table(\n",
    "        obs_clean,\n",
    "        index=\"userId\",\n",
    "        columns=\"page\",\n",
    "        values=\"ts\",\n",
    "        aggfunc=\"count\",\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "\n",
    "    useful_pages = [\"Thumbs Up\", \"Thumbs Down\", \"Roll Advert\", \"Error\", \"Upgrade\", \"Downgrade\", \"Add to Playlist\"]\n",
    "    behavior_df = page_counts[[\"userId\"] + [p for p in useful_pages if p in page_counts.columns]]\n",
    "\n",
    "    if \"Thumbs Up\" in behavior_df and \"Thumbs Down\" in behavior_df:\n",
    "        behavior_df[\"satisfaction_ratio\"] = behavior_df[\"Thumbs Up\"] / (behavior_df[\"Thumbs Down\"] + 1)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 3. Trends features\n",
    "    # ----------------------------------------\n",
    "    T_recent = T0 - pd.Timedelta(days=WINDOW_RECENT)\n",
    "    recent = obs_clean[obs_clean[\"ts\"] >= T_recent]\n",
    "\n",
    "    recent_stats = recent.groupby(\"userId\")[\"length\"].sum().reset_index().rename(columns={\"length\": \"listen_time_recent\"})\n",
    "    trends = global_feats[[\"userId\", \"avg_daily_listen\"]].merge(recent_stats, on=\"userId\", how=\"left\").fillna(0)\n",
    "\n",
    "    trends[\"avg_daily_listen_recent\"] = trends[\"listen_time_recent\"] / WINDOW_RECENT\n",
    "    trends[\"trend_listening\"] = trends[\"avg_daily_listen_recent\"] / (trends[\"avg_daily_listen\"] + 0.01)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4. Device features\n",
    "    # ----------------------------------------\n",
    "    last_agent = obs_clean.sort_values(\"ts\").groupby(\"userId\")[\"userAgent\"].last().reset_index()\n",
    "\n",
    "    def flag(pattern): \n",
    "        return last_agent[\"userAgent\"].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "    last_agent[\"is_mac\"] = flag(\"Macintosh\")\n",
    "    last_agent[\"is_windows\"] = flag(\"Windows\")\n",
    "    last_agent[\"is_linux\"] = flag(\"Linux\")\n",
    "    last_agent[\"is_mobile\"] = flag(\"iPhone|iPad|Android|Mobile\")\n",
    "    last_agent[\"is_firefox\"] = flag(\"Firefox\")\n",
    "    last_agent[\"is_chrome\"] = flag(\"Chrome\")\n",
    "\n",
    "    tech = last_agent[[\"userId\", \"is_mac\", \"is_windows\", \"is_linux\", \"is_mobile\", \"is_firefox\", \"is_chrome\"]]\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # üîß Merge final\n",
    "    # ----------------------------------------\n",
    "    df_snapshot = target_df.merge(global_feats, on=\"userId\", how=\"left\")\\\n",
    "        .merge(behavior_df, on=\"userId\", how=\"left\")\\\n",
    "        .merge(trends[[\"userId\", \"trend_listening\"]], on=\"userId\", how=\"left\")\\\n",
    "        .merge(windows_df, on=\"userId\", how=\"left\") \\\n",
    "        .merge(tech, on=\"userId\", how=\"left\")\\\n",
    "        .fillna(0)\n",
    "\n",
    "    df_snapshot[\"snapshot_time\"] = T0  # cl√© temporelle utilis√©e par TimeSeriesSplit\n",
    "\n",
    "    return df_snapshot\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîÅ Boucle sur tous les T0\n",
    "# ----------------------------------------\n",
    "snapshots = []\n",
    "for T0 in T0_list:\n",
    "    snap = compute_snapshot(df, T0)\n",
    "    snapshots.append(snap)\n",
    "\n",
    "# concat√©nation\n",
    "final = pd.concat(snapshots, ignore_index=True)\n",
    "\n",
    "# sauvegarde\n",
    "final.to_parquet(OUTPUT_PATH, index=False)\n",
    "print(f\"\\nüéâ Dataset multi-snapshot sauvegard√© dans {OUTPUT_PATH}\")\n",
    "print(f\"Final shape = {final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468c7d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_features_multisnapshot.parquet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()\n",
    "OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed24d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identification des churners dans le futur\n",
    "# churners_future = future[future[\"page\"] == \"Cancellation Confirmation\"][\"userId\"].unique()\n",
    "\n",
    "# # Cr√©ation du DataFrame final avec la colonne 'target'\n",
    "# target_df = pd.DataFrame({\"userId\": users_population})\n",
    "\n",
    "# # Si l'user est dans la liste des churners futurs, target = 1, sinon 0\n",
    "# target_df[\"target\"] = target_df[\"userId\"].isin(churners_future).astype(int)\n",
    "\n",
    "# print(\"üéØ Distribution de la cible (Combien de churners ?) :\")\n",
    "# print(target_df[\"target\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b687914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"üèóÔ∏è Calcul des features globales...\")\n",
    "\n",
    "# global_feats = obs_clean.groupby(\"userId\").agg({\n",
    "#     \"ts\": \"max\",                      # Date de derni√®re action\n",
    "#     \"date\": \"nunique\",                # Nombre de jours actifs totaux\n",
    "#     \"sessionId\": \"nunique\",           # Nombre de sessions totales\n",
    "#     \"length\": \"sum\",                  # Temps total d'√©coute\n",
    "#     \"registration\": \"min\"             # Date d'inscription\n",
    "# }).reset_index()\n",
    "\n",
    "# global_feats.columns = [\"userId\", \"last_ts\", \"n_active_days\", \"n_sessions\", \"total_listening_time\", \"registration_ts\"]\n",
    "\n",
    "# # Conversion date inscription\n",
    "# global_feats[\"registration_ts\"] = pd.to_datetime(global_feats[\"registration_ts\"], unit=\"ms\")\n",
    "\n",
    "# # Feature 1 : R√©cence (Jours √©coul√©s depuis la derni√®re action avant T0)\n",
    "# global_feats[\"recency_days\"] = (T0 - global_feats[\"last_ts\"]).dt.days\n",
    "\n",
    "# # Feature 2 : Anciennet√© du compte en jours\n",
    "# global_feats[\"account_age_days\"] = (T0 - global_feats[\"registration_ts\"]).dt.days\n",
    "\n",
    "# # Feature 3 : Temps d'√©coute moyen par jour d'anciennet√©\n",
    "# global_feats[\"avg_daily_listen\"] = global_feats[\"total_listening_time\"] / (global_feats[\"account_age_days\"] + 1)\n",
    "\n",
    "# display(global_feats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853e72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"üëç Calcul des indicateurs de comportement (Likes, Erreurs)...\")\n",
    "\n",
    "# # Pivot table : cr√©e une colonne pour chaque type de page\n",
    "# page_counts = pd.pivot_table(\n",
    "#     obs_clean, \n",
    "#     index=\"userId\", \n",
    "#     columns=\"page\", \n",
    "#     values=\"ts\", \n",
    "#     aggfunc=\"count\", \n",
    "#     fill_value=0\n",
    "# ).reset_index()\n",
    "\n",
    "# # On s√©lectionne seulement les pages utiles\n",
    "# useful_pages = [\"Thumbs Up\", \"Thumbs Down\", \"Roll Advert\", \"Error\", \"Upgrade\", \"Downgrade\", \"Add to Playlist\"]\n",
    "# cols_to_keep = [\"userId\"] + [col for col in useful_pages if col in page_counts.columns]\n",
    "# behavior_df = page_counts[cols_to_keep].copy()\n",
    "\n",
    "# # Ratio de Satisfaction : (Likes) / (Dislikes + 1)\n",
    "# if \"Thumbs Up\" in behavior_df and \"Thumbs Down\" in behavior_df:\n",
    "#     behavior_df[\"satisfaction_ratio\"] = behavior_df[\"Thumbs Up\"] / (behavior_df[\"Thumbs Down\"] + 1)\n",
    "\n",
    "# display(behavior_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d12d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(\"üìà Calcul des tendances (Activit√© r√©cente vs Habitude)...\")\n",
    "\n",
    "# # # 1. On prend seulement les logs des 14 derniers jours avant T0\n",
    "# # T_recent = T0 - pd.Timedelta(days=14)\n",
    "# # obs_recent = obs_clean[obs_clean[\"ts\"] >= T_recent]\n",
    "\n",
    "# # # 2. On calcule le temps d'√©coute sur cette p√©riode r√©cente\n",
    "# # recent_stats = obs_recent.groupby(\"userId\").agg({\n",
    "# #     \"length\": \"sum\"     \n",
    "# # }).reset_index().rename(columns={\"length\": \"listen_time_recent\"})\n",
    "\n",
    "# # # 3. On merge avec les stats globales pour comparer\n",
    "# # trends = global_feats[[\"userId\", \"avg_daily_listen\"]].merge(recent_stats, on=\"userId\", how=\"left\").fillna(0)\n",
    "\n",
    "# # # 4. Moyenne quotidienne R√âCENTE\n",
    "# # trends[\"avg_daily_listen_recent\"] = trends[\"listen_time_recent\"] / 14\n",
    "\n",
    "# # # 5. RATIO (TREND) : R√©cent / Habitude\n",
    "# # # Si < 1 : L'utilisateur ralentit -> Risque de Churn\n",
    "# # trends[\"trend_listening\"] = trends[\"avg_daily_listen_recent\"] / (trends[\"avg_daily_listen\"] + 0.01)\n",
    "\n",
    "# # display(trends[[\"userId\", \"trend_listening\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eae7c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === A AJOUTER DANS NOTEBOOK 01 (Avant la fusion finale) ===\n",
    "# print(\"üíª Extraction des features techniques (OS & Device)...\")\n",
    "\n",
    "# # On prend le dernier userAgent connu pour chaque utilisateur\n",
    "# last_agent = obs_clean.sort_values(\"ts\").groupby(\"userId\")[\"userAgent\"].last().reset_index()\n",
    "\n",
    "# # Cr√©ation manuelle des flags (plus s√ªr que get_dummies pour la compatibilit√© Train/Test)\n",
    "# # 1. Syst√®me d'exploitation\n",
    "# last_agent[\"is_mac\"] = last_agent[\"userAgent\"].str.contains(\"Macintosh\", case=False, na=False).astype(int)\n",
    "# last_agent[\"is_windows\"] = last_agent[\"userAgent\"].str.contains(\"Windows\", case=False, na=False).astype(int)\n",
    "# last_agent[\"is_linux\"] = last_agent[\"userAgent\"].str.contains(\"Linux\", case=False, na=False).astype(int)\n",
    "# last_agent[\"is_mobile\"] = last_agent[\"userAgent\"].str.contains(\"iPhone|iPad|Android|Mobile\", case=False, na=False).astype(int)\n",
    "\n",
    "# # 2. Navigateur (les utilisateurs Chrome/Firefox ont souvent des profils diff√©rents des utilisateurs IE/Safari)\n",
    "# last_agent[\"is_firefox\"] = last_agent[\"userAgent\"].str.contains(\"Firefox\", case=False, na=False).astype(int)\n",
    "# last_agent[\"is_chrome\"] = last_agent[\"userAgent\"].str.contains(\"Chrome\", case=False, na=False).astype(int)\n",
    "\n",
    "# # On garde uniquement les nouvelles colonnes\n",
    "# tech_features = last_agent[[\"userId\", \"is_mac\", \"is_windows\", \"is_linux\", \"is_mobile\", \"is_firefox\", \"is_chrome\"]]\n",
    "\n",
    "# print(f\"‚úÖ Features techniques pr√™tes. Shape : {tech_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7291bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"üß© Fusion finale des features...\")\n",
    "\n",
    "# # On part de la target et on ajoute tout\n",
    "# final_df = target_df.merge(global_feats, on=\"userId\", how=\"left\")\n",
    "# final_df = final_df.merge(behavior_df, on=\"userId\", how=\"left\")\n",
    "# final_df = final_df.merge(trends[[\"userId\", \"trend_listening\"]], on=\"userId\", how=\"left\")\n",
    "# final_df = final_df.merge(tech_features, on=\"userId\", how=\"left\").fillna(0)\n",
    "# # Remplacer les vides par 0\n",
    "# final_df = final_df.fillna(0)\n",
    "\n",
    "# # Nettoyage des colonnes dates inutiles pour le mod√®le\n",
    "# cols_to_drop = [\"last_ts\", \"registration_ts\"]\n",
    "# final_df = final_df.drop(columns=[c for c in cols_to_drop if c in final_df.columns])\n",
    "\n",
    "# print(f\"‚úÖ Termin√© ! Shape finale : {final_df.shape}\")\n",
    "# final_df.to_parquet(OUTPUT_PATH, index=False)\n",
    "# print(f\"üíæ Fichier sauvegard√© : {OUTPUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
